{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapting the below scripts to Places2\n",
    "\n",
    "Directory: https://github.com/fastai/imagenet-fast/tree/master/imagenet_nv\n",
    "\n",
    "CIFAR10 training notebook: https://github.com/fastai/imagenet-fast/blob/master/cifar10/cifar10-super-convergence-more-aug.ipynb\n",
    "\n",
    "Imagenet training script: https://github.com/fastai/imagenet-fast/blob/master/imagenet_nv/main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bn', 'bnf_resnet50', 'bnz_resnet50', 'conv3x3', 'darknet_50', 'darknet_mini', 'darknet_mini2', 'darknet_mini3', 'darknet_small', 'dpn107', 'dpn131', 'dpn68', 'dpn92', 'dpn98', 'inceptionresnetv2', 'inceptionresnetv2_conc', 'inceptionv4', 'load', 'load_block17', 'load_block35', 'load_block8', 'load_conv2d', 'load_conv2d_nobn', 'load_linear', 'load_mixed_4a_7a', 'load_mixed_5', 'load_mixed_5b', 'load_mixed_6', 'load_mixed_6a', 'load_mixed_7', 'load_mixed_7a', 'pre_resnet101', 'pre_resnet152', 'pre_resnet18', 'pre_resnet34', 'pre_resnet50', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnet50_3', 'resnext101', 'resnext152', 'resnext18', 'resnext34', 'resnext50', 'se_resnet_101', 'se_resnet_152', 'se_resnet_18', 'se_resnet_34', 'se_resnet_50', 'se_resnet_50_conc', 'se_resnext_101', 'se_resnext_152', 'se_resnext_50', 'test', 'test_block17', 'test_block35', 'test_block8', 'test_conv2d', 'test_conv2d_nobn', 'test_mixed_4a_7a', 'test_mixed_5b', 'test_mixed_6a', 'test_mixed_7a', 'w125_resnet50', 'w15_resnet50']\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, shutil, time, warnings, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.dataset import *\n",
    "from fastai.fp16 import *\n",
    "from fastai.conv_learner import *\n",
    "from pathlib import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pytorch_models\n",
    "from fp16util import network_to_half, set_grad, copy_in_params\n",
    "\n",
    "\n",
    "# print(models.cifar10.__dict__)\n",
    "model_names = sorted(name for name in pytorch_models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(pytorch_models.__dict__[name]))\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--rank'], dest='rank', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help=\"Used for multi-process training. Can either be manually set or automatically set by using 'python -m multiproc'.\", metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage: python run_fastai.py /home/paperspace/ILSVRC/Data/CLS-LOC/ -a resnext_50_32x4d --epochs 1 -j 4 -b 64 --fp16\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Places2 Training')\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                 help='path to dataset')\n",
    "parser.add_argument('--save-dir', type=str, default=Path.home()/'imagenet_training',\n",
    "                    help='Directory to save logs and models.')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(model_names) +\n",
    "                    ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=7, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 7)')\n",
    "parser.add_argument('--epochs', default=1, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "#parser.add_argument('--cycle-len', default=95, type=float, metavar='N',\n",
    "#                    help='Length of cycle to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=100, type=int,\n",
    "                    metavar='N', help='print frequency (default: 100 iterations)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')\n",
    "parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "parser.add_argument('--use-tta', default=True, type=bool, help='Validate model with TTA at the end of traiing.')\n",
    "parser.add_argument('--train-half', action='store_true', help='Train model on half images. TODO: allow custom epochs and LR')\n",
    "parser.add_argument('--sz',       default=256, type=int, help='Size of transformed image.')\n",
    "parser.add_argument('--decay-int', default=30, type=int, help='Decay LR by 10 every decay-int epochs')\n",
    "#parser.add_argument('--use-clr', default='10,13.68,0.95,0.85', type=str, \n",
    "#                    help='div,pct,max_mom,min_mom. Pass in a string delimited by commas. Ex: \"20,2,0.95,0.85\"')\n",
    "parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                    help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "parser.add_argument('--prof', dest='prof', action='store_true', help='Only run a few iters for profiling.')\n",
    "\n",
    "parser.add_argument('--world-size', default=1, type=int,\n",
    "                    help='Number of GPUs to use. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')\n",
    "parser.add_argument('--rank', default=0, type=int,\n",
    "                    help='Used for multi-process training. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(traindir, valdir):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    tensor_tfm = [transforms.ToTensor(), normalize]\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(args.sz),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ] + tensor_tfm))\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(int(args.sz*1.14)),\n",
    "            transforms.CenterCrop(args.sz),\n",
    "        ] + tensor_tfm)),\n",
    "        batch_size=args.batch_size*2, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=False)\n",
    "\n",
    "    return train_loader,val_loader,train_sampler\n",
    "\n",
    "\n",
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return t[0]\n",
    "\n",
    "    \n",
    "class data_prefetcher():\n",
    "    def __init__(self, loader, prefetch=True):\n",
    "        self.loader,self.prefetch = iter(loader),prefetch\n",
    "        if prefetch:\n",
    "            self.stream = torch.cuda.Stream()\n",
    "            self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def next(self):\n",
    "        if not self.prefetch:\n",
    "            input,target = next(self.loader)\n",
    "            return input.cuda(async=True),target.cuda(async=True)\n",
    "\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        target = self.next_target\n",
    "        self.preload()\n",
    "        return input, target\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    prefetcher = data_prefetcher(train_loader, prefetch=True)\n",
    "    input, target = prefetcher.next()\n",
    "    i = -1\n",
    "    while input is not None:\n",
    "        i += 1\n",
    "\n",
    "        if args.prof and (i > 200): break\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        if args.distributed:\n",
    "            reduced_loss = reduce_tensor(loss.data)\n",
    "            prec1 = reduce_tensor(prec1)\n",
    "            prec5 = reduce_tensor(prec5)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        # compute gradient and do SGD step\n",
    "\n",
    "        if args.fp16:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            set_grad(param_copy, list(model.parameters()))\n",
    "\n",
    "            if args.loss_scale != 1:\n",
    "                for param in param_copy:\n",
    "                    param.grad.data = param.grad.data/args.loss_scale\n",
    "\n",
    "            optimizer.step()\n",
    "            copy_in_params(model, param_copy)\n",
    "            torch.cuda.synchronize()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "\n",
    "        end = time.time()\n",
    "        input, target = prefetcher.next()\n",
    "\n",
    "        if args.rank == 0 and i % args.print_freq == 0 and i > 1:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    prefetcher = data_prefetcher(val_loader)\n",
    "    input, target = prefetcher.next()\n",
    "    i = -1\n",
    "    while input is not None:\n",
    "        i += 1\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "        reduced_loss = reduce_tensor(loss.data)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        reduced_prec1 = reduce_tensor(prec1)\n",
    "        reduced_prec5 = reduce_tensor(prec5)\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if args.rank == 0 and i % args.print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "\n",
    "        input, target = prefetcher.next()\n",
    "\n",
    "    time_diff = datetime.now()-start_time\n",
    "    print(f'~~{epoch}\\t{float(time_diff.total_seconds() / 3600.0)}\\t{top5.avg:.3f}\\n')\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, f'{args.save_dir}/model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every few epochs\"\"\"\n",
    "    if   epoch<4 : lr = args.lr/(4-epoch)\n",
    "    elif epoch<28: lr = args.lr/1\n",
    "    elif epoch<47: lr = args.lr/10\n",
    "    elif epoch<57: lr = args.lr/100\n",
    "    else         : lr = args.lr/1000\n",
    "    for param_group in optimizer.param_groups: param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    'data', \n",
    "    '--save-dir', 'training/test1', \n",
    "#     '-a', 'resnext29_8_64', \n",
    "#     '-j', '6', \n",
    "#     '--prof', \n",
    "    '-b', '512', \n",
    "#     '--sz', '32',\n",
    "#     '--loss-scale', '128',\n",
    "    '--fp16',\n",
    "#     '--epochs', '1',\n",
    "#     '--use-clr', '10,13.68,0.95,0.85',\n",
    "#    '--wd', '2e-4',\n",
    "#    '--lr', '1',\n",
    "     '--train-half' # With fp16, iterations are so fast this doesn't matter\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arch='resnet18', batch_size=512, data='data', decay_int=30, distributed=False, epochs=1, evaluate=False, fp16=True, loss_scale=1, lr=0.1, momentum=0.9, pretrained=False, print_freq=100, prof=False, rank=0, resume='', save_dir='training/test1', start_epoch=0, sz=256, train_half=True, use_tta=True, weight_decay=0.0001, workers=7, world_size=1)\n"
     ]
    }
   ],
   "source": [
    "# This is important for speed \n",
    "cudnn.benchmark = True\n",
    "\n",
    "global arg\n",
    "args = parser.parse_args(args_input); \n",
    "args.distributed = args.world_size > 1\n",
    "print(args)\n",
    "\n",
    "if args.fp16:\n",
    "    assert torch.backends.cudnn.enabled, \"fp16 mode requires cudnn backend to be enabled.\"\n",
    "    \n",
    "#global arg\n",
    "#args = parser.parse_args(args_input); args\n",
    "#if args.cycle_len > 1: args.cycle_len = int(args.cycle_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "if args.pretrained: \n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "    model = pytorch_models.__dict__[args.arch](pretrained=True)\n",
    "else: \n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "    model = pytorch_models.__dict__[args.arch]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "if args.fp16: model = network_to_half(model)\n",
    "\n",
    "global param_copy\n",
    "if args.fp16:\n",
    "    param_copy = [param.clone().type(torch.cuda.FloatTensor).detach() for param in model.parameters()]\n",
    "    for param in param_copy: param.requires_grad = True\n",
    "else: param_copy = list(model.parameters())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(param_copy, args.lr, momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        checkpoint = torch.load(args.resume, map_location = lambda storage, loc: storage.cuda(args.gpu))\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    else: print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'valid')\n",
    "train_loader,val_loader,train_sampler = get_loaders(traindir, valdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if args.evaluate: return validate(val_loader, model, criterion, epoch, start_time)\n",
    "#validate(val_loader, model, criterion, epoch, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "adjust_learning_rate(optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is some trick we will try later ...\n",
    "# in last few epochs, use different image size to train\n",
    "#if epoch==args.epochs-6:\n",
    "#    args.sz=288\n",
    "#    args.batch_size=128\n",
    "#    train_loader,val_loader,train_sampler,val_sampler = get_loaders(\n",
    "#        traindir, valdir, use_val_sampler=False, min_scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/3523]\tTime 0.563 (0.599)\tData 0.258 (0.225)\tLoss 5.3750 (5.7704)\tPrec@1 2.344 (1.412)\tPrec@5 9.961 (5.736)\n",
      "Epoch: [1][200/3523]\tTime 0.459 (0.560)\tData 0.151 (0.218)\tLoss 5.0352 (5.4744)\tPrec@1 4.297 (2.452)\tPrec@5 13.867 (9.100)\n",
      "Epoch: [1][300/3523]\tTime 0.312 (0.547)\tData 0.001 (0.216)\tLoss 4.7305 (5.2760)\tPrec@1 7.422 (3.492)\tPrec@5 22.266 (12.089)\n",
      "Epoch: [1][400/3523]\tTime 1.348 (0.541)\tData 1.029 (0.215)\tLoss 4.4414 (5.1231)\tPrec@1 9.961 (4.436)\tPrec@5 28.320 (14.643)\n",
      "Epoch: [1][500/3523]\tTime 0.311 (0.535)\tData 0.001 (0.212)\tLoss 4.3633 (4.9987)\tPrec@1 8.594 (5.307)\tPrec@5 28.320 (16.866)\n",
      "Epoch: [1][600/3523]\tTime 0.315 (0.531)\tData 0.001 (0.210)\tLoss 4.2852 (4.8971)\tPrec@1 11.914 (6.057)\tPrec@5 30.664 (18.747)\n",
      "Epoch: [1][700/3523]\tTime 0.312 (0.529)\tData 0.001 (0.208)\tLoss 4.1953 (4.8078)\tPrec@1 11.328 (6.803)\tPrec@5 32.227 (20.481)\n",
      "Epoch: [1][800/3523]\tTime 0.314 (0.528)\tData 0.002 (0.209)\tLoss 4.1250 (4.7270)\tPrec@1 11.328 (7.536)\tPrec@5 34.375 (22.122)\n",
      "Epoch: [1][900/3523]\tTime 0.487 (0.528)\tData 0.178 (0.210)\tLoss 4.1484 (4.6559)\tPrec@1 11.719 (8.204)\tPrec@5 31.641 (23.580)\n",
      "Epoch: [1][1000/3523]\tTime 0.309 (0.527)\tData 0.001 (0.209)\tLoss 3.9238 (4.5915)\tPrec@1 18.164 (8.848)\tPrec@5 38.477 (24.910)\n",
      "Epoch: [1][1100/3523]\tTime 1.259 (0.527)\tData 0.951 (0.210)\tLoss 4.0234 (4.5330)\tPrec@1 14.844 (9.450)\tPrec@5 36.328 (26.108)\n",
      "Epoch: [1][1200/3523]\tTime 0.313 (0.526)\tData 0.001 (0.209)\tLoss 3.8398 (4.4788)\tPrec@1 16.406 (10.015)\tPrec@5 41.602 (27.257)\n",
      "Epoch: [1][1300/3523]\tTime 0.310 (0.525)\tData 0.001 (0.209)\tLoss 3.7305 (4.4266)\tPrec@1 18.359 (10.593)\tPrec@5 43.555 (28.391)\n",
      "Epoch: [1][1400/3523]\tTime 0.311 (0.527)\tData 0.002 (0.211)\tLoss 3.6172 (4.3813)\tPrec@1 16.211 (11.111)\tPrec@5 46.680 (29.397)\n",
      "Epoch: [1][1500/3523]\tTime 0.312 (0.529)\tData 0.001 (0.213)\tLoss 3.6621 (4.3377)\tPrec@1 21.289 (11.620)\tPrec@5 44.727 (30.331)\n",
      "Epoch: [1][1600/3523]\tTime 0.311 (0.529)\tData 0.001 (0.214)\tLoss 3.6680 (4.2975)\tPrec@1 18.555 (12.074)\tPrec@5 45.898 (31.192)\n",
      "Epoch: [1][1700/3523]\tTime 1.696 (0.529)\tData 1.385 (0.214)\tLoss 3.6133 (4.2598)\tPrec@1 19.922 (12.517)\tPrec@5 45.117 (32.006)\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "# Time 0.563 (0.599) : the current 1-batch processing time in sec (running average)\n",
    "# Data 0.258 (0.225) : the current batch loading time in sec (running average)\n",
    "# Prec@1 2.344 (1.412) : top 1-category accuracy in % (running average)\n",
    "# Prec@5 9.961 (5.736) : top 5-category accuracy in % (running average)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    train(train_loader, model, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'ctime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4e7ad24b21c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'ctime'"
     ]
    }
   ],
   "source": [
    "datetime.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'no_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8f58401a94f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-8ca14adefc02>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, model, criterion, epoch, start_time)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'no_grad'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prec1 = validate(val_loader, model, criterion, epoch, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
